{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../likelihood/\")\n",
    "\n",
    "import PSR_counts as gc\n",
    "from likelihood import ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The expected number of PS counts\n",
    "\n",
    "Here, we describe how we calculate the expected number of PS counts, given the model parameters.  These computations are implemented in the file `get_counts_inline.pyx` in the `likelihood/` subfolder.  First, we describe the computation for a general PS population, with density function $\\rho(s,\\ell,b)$, where $(s,\\ell,b)$ are spatial coordinates with origin at the Earth, and luminosity function $dN/dL$.  Note that $\\ell$ and $b$ are Galactic longitude and latitude, respectively, while $s$ is the distance from the Earth.  The expected number of counts in a given spatial bin (labeled by $i,j$) and flux bin (labelled by $k$) is given by the integral\n",
    "\n",
    "$$\n",
    "N_{i,j,k} = \\omega_{i,j,k} \\int_{\\Delta \\Omega_{i,j}} d\\ell d b \\rho(s,\\ell,b) s^2 \\int_{4 \\pi s^2 S_k^\\text{min}}^{4 \\pi s^2 S_k^\\text{max}} {dN \\over dL} dL \\,,\n",
    "$$ \n",
    "\n",
    "where $\\omega_{i,j,k}$ is the efficiency factor for pulsar-like PS detection in that bin.  Note that we have assumed that $\\omega_{i,j,k}$ is constant within the bin, so that we may bring it outside of the integral.\n",
    " \n",
    "\n",
    "In the code, for both the disk and the Bulge, we normalize both $\\rho$ and $dN/dL$ such that the full integral over all of space and flux is equal to the total number of sources $N$ for that population.  The number of sources is one of the model parameters.  To work with this convention, we must know how to properly normalize $\\rho$ and $dN/dL$ .\n",
    "\n",
    "The normalization of $dN/dL$ is common to both the disk and Bulge.  Let \n",
    "\n",
    "$$\n",
    "{dN \\over dL} = {N_0 \\over L^\\beta}\n",
    "$$\n",
    "\n",
    "for $L$ in the range $[L_\\text{min}, L_\\text{max}]$ and be zero outside of this range.  We will normalize $dN/dL$ so that it integrates to unity, which implies that\n",
    " \n",
    "$$\n",
    "N_0 = {\\beta - 1 \\over L_\\text{min}^{1-\\beta} - L_\\text{max}^{1 - \\beta} } \\,.\n",
    "$$  \n",
    "\n",
    "\n",
    "We discuss $\\rho$ now for the disk and Bulge.  We will use the normalization that $\\int d^3x \\rho = N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we take a few artibtrary choices to illustrate to functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_stars = 10.0 #example, why not\n",
    "omega_ijk = 1.0 #example, why not\n",
    "i=3 #example, why not\n",
    "j=3 #example, why not\n",
    "k=1 #example, why not\n",
    "\n",
    "Ns = 100 #number of s bins in s integration\n",
    "Nang = 2 #number of angular bins in angular integration\n",
    "\n",
    "\n",
    "#These are also adjustable \n",
    "Lmin=1.0e31\n",
    "Lmax = 1.0e36\n",
    "\n",
    "#Theta mask: this masks the inner \\theta degrees when calculating the expected number of counts\n",
    "theta_mask = 2.0 #degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Bulge sources \n",
    "\n",
    "We characterize the Bulge PS population by\n",
    "\n",
    "$$\n",
    "\\rho_\\text{bulge} = {C \\over r^\\alpha} \\,,\n",
    "$$\n",
    "\n",
    "where $r$ is the distance from the Galactic Center, so long as $r < r_\\text{cut}$ .  $\\rho$ is equal to zero for larger values of $r$ .  To have to proper normalization, it is straightforward to verify that\n",
    " \n",
    "$$\n",
    "C = {(3 - \\alpha) N_\\text{bulge} \\over 4 \\pi r_\\text{cut}^{3 - \\alpha} } \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2.60\n",
    "beta=1.20\n",
    "rcut = 3.0 #kpc\n",
    "\n",
    "N_bulge = gc.Nbulge_full_ang_ijk(i,j,k,N_stars,omega_ijk,alpha,beta,rcut,Lmin,Lmax,Ns,Nang,theta_mask) \n",
    "print N_bulge\n",
    "\n",
    "n = 2.35\n",
    "z0 = 0.7 #kpc\n",
    "sigma = 1.528 #kpc\n",
    "beta=1.20\n",
    "\n",
    "smax = 40.0 #kpc , how far out to integrate to?\n",
    "\n",
    "N_disk = gc.Ndisk_full_ang_ijk(i,j,k,N_stars,omega_ijk,n,sigma,z0,beta,Lmin,Lmax,Ns,Nang,smax,theta_mask) \n",
    "print N_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Disk sources\n",
    "\n",
    "The disk is modeled by the distribution \n",
    "\n",
    "$$\n",
    "\\rho_\\text{disk} = C R^n e^{-R / \\sigma} e^{-|z| / z_0} \\,,\n",
    "$$\n",
    "\n",
    "and we find that in this case\n",
    "\n",
    "$$\n",
    "C = {N_\\text{disk} \\over 4 \\pi z_0 \\sigma^{n+2} \\Gamma(n+2)} \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 2.35\n",
    "z0 = 0.7 #kpc\n",
    "sigma = 1.528 #kpc\n",
    "beta=1.20\n",
    "\n",
    "smax = 40.0 #kpc , how far out to integrate to?\n",
    "\n",
    "N_disk = gc.Ndisk_full_ang_ijk(i,j,k,N_stars,omega_ijk,n,sigma,z0,beta,Lmin,Lmax,Ns,Nang,smax,theta_mask) \n",
    "print N_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the total number of total bulge and disk counts, for the prior.\n",
    "Here, we integrate over fluxes from $1.8 \\times 10^{-5}$ MeV cm$^{-2}$ s$^{-1}$ to $6.539 \\times 10^{-4}$ MeV cm$^{-2}$ s$^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nang_total = 100 #We use a larger number of angular bins here, since we are integrating over the full sky\n",
    "N_bulge_total = gc.Nbulge_total(N_stars,alpha,beta,rcut,Lmin,Lmax,Ns,Nang_total,theta_mask)\n",
    "N_disk_total = gc.Ndisk_total(N_stars,n,sigma,z0,beta,Lmin,Lmax,Ns,Nang_total,smax,theta_mask)\n",
    "print N_bulge_total,N_disk_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The likelihood function\n",
    "\n",
    "The `GCE-2FIG` code package uses the likelihood function presented in [1705.00009](https://arxiv.org/pdf/1705.00009.pdf).  The likelihood is implemented in the file `likelihood.pyx` in the `likelihood/` subfolder.  The sky is spatially binned in a cartesian grid, and the data consists of the number of pulsar candidates detected in each bin.  The model parameters characterize the disk and Bulge point source populations, and as we scan over the model parameters we calculated the expected number of detected sources in each bin, utilizing the _Fermi_-provided efficiency function for detecting sources at a given flux and spatial position.  The likelihood is then given by the product over all pixels of the Poisson probabilities to observe the data counts given the predicted model counts.\n",
    "\n",
    "As an option, we also incorporate the prior distribution in [1705.00009](https://arxiv.org/pdf/1705.00009.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Appendix: code implementation\n",
    "\n",
    "Here, we describe in more detail how we implement the computations of the expected number of PS counts in the file `get_counts_inline.pyx`.\n",
    "\n",
    "The cartesian grid is given by 12 linear-spaced bins in the inner 40$^\\circ$ of the Milky Way:\n",
    "\n",
    "```c\n",
    "cdef double[::1] ang_boundaries = np.linspace(-20.,20.,13,dtype=DTYPE)\n",
    "``` \n",
    "\n",
    "The flux-bin boundaries are given by\n",
    "\n",
    "```python\n",
    "fluxvals = [1.00000000e-06, 1.46779927e-06, 2.15443469e-06, 3.16227766e-06, 4.64158883e-06, 6.81292069e-06, 1.00000000e-05, 3.16227766e-05, 1.00000000e-04]\n",
    "```\n",
    "\n",
    "in units of MeV/cm^2/s.\n",
    "\n",
    "The function \n",
    "\n",
    "```c\n",
    "double Nbulge_full_ang_ijk(int i, int j, int k, double Nbulge, double omega_ijk, double alpha, double beta,double rcut , double Lmin, double Lmax ,int Ns ,int Nang, double theta_mask )\n",
    "```\n",
    "\n",
    "return the number of counts in the Bulge in spatial $\\ell$ bin `i`, $b$ bin `j`, and flux bin `k`.  Most of the parameters above are defined previously.  However, there are a few parameters that are specific to the calculation method.  These include\n",
    "\n",
    "    1. int Ns: the number of points in the numerical integral over s\n",
    "    2. int Nang: the number of latitude and longitude points in the numerical integral over the pixel\n",
    "    3. double theta_mask: the radius in degrees fro the Galactic Center that will be masked when computing the number of counts\n",
    "  \n",
    "The code itself proceeds by first initializing relevant quantities, such as\n",
    "\n",
    "```python\n",
    "cdef double ell_start = ang_boundaries[i]\n",
    "cdef double b_start = ang_boundaries[j]\n",
    "cdef double d_ang = (ang_boundaries[1] - ang_boundaries[0])/float(Nang)\n",
    "```\n",
    "\n",
    "and  calculating relevant pre-factors, such as \n",
    "\n",
    "```python\n",
    "pref_rho = omega_ijk * Nbulge * (3. - alpha) / 4. / pi / pow(rcut,3 - alpha)\n",
    "```\n",
    "\n",
    "and \n",
    "\n",
    "```python\n",
    "pref_L_norm = 1./(pow(Lmin,1-beta) - pow(Lmax,1-beta))\n",
    "```\n",
    "\n",
    "Then, the bulk of the code proceeds through the loops used to perform the angular integration and the integration over $s$:\n",
    "\n",
    "```python\n",
    "for i_b in range(Nang):\n",
    "    b = b_start + i_b*d_ang + d_ang/2.\n",
    "    for i_ell in range(Nang):\n",
    "        ell = ell_start + i_ell*d_ang + d_ang/2.\n",
    "        coslval = cos(ell * degtorad)\n",
    "        cosbval = cos(b * degtorad)\n",
    "\n",
    "        if cosbval * coslval < costhetaval: #is it masked?\n",
    "\n",
    "            incl = 1. - (1. - pow(rcut/rodot,2) ) * pow(coslval*cosbval,2)\n",
    "            if incl > 0: # should we bother, or is the answer going to be zero?\n",
    "                integral = 0.0\n",
    "                s = smin\n",
    "                for l in range(Ns): #Loop over `s` for `s` integral\n",
    "\n",
    "                    flux_min_eval = max(Lmin/s**2,4*pi*fluxmin)\n",
    "                    flux_max_eval = min(Lmax/s**2,4*pi*fluxmax)\n",
    "\n",
    "                    if flux_max_eval < flux_min_eval:\n",
    "                        pref_L = 0.0\n",
    "                    else:\n",
    "                        pref_L = (pow(flux_min_eval, 1.-beta) - pow(flux_max_eval, 1.-beta))*pref_L_norm\n",
    "\n",
    "                    r_squared = (s*cosbval*coslval - rodot)**2 + s**2*(1. - pow(cosbval*coslval,2) )\n",
    "                    if r_squared < pow(rcut,2):\n",
    "                        integral += pref_L * pow(s,4.-2.*beta)*pow(r_squared,-alpha/2.)\n",
    "                    s += ds\n",
    "\n",
    "                total_res += cosbval * integral \n",
    "```\n",
    "\n",
    "Above, `i_ell` is the index over longitude, `i_b` is the index of latitude, and `l` is the index over the $s$ bins.  In the first few lines we simply update the new values for `b` and `ell` and their cosines.  We then see if these values of `b` and `ell` are masked.  The statement `if incl > 0:` looks to see if we are too far away from the GC, such that we will completely miss the bulge.  This is relevant given the finite extent of the bulge, but this step is not needed for the disk contribution.  Then, we begin looping over the `s` integral, through the index `l`.  First, we find the true limits of the flux integral, given that fact that the luminosity function is cut off at `Lmin` and `Lmax`.  Then, we perform the integral over `L` to get `pref_L`.  The quantity `integral` contains both the integral over `s` and the integral over `L`.  \n",
    "\n",
    "Finally, we return \n",
    "\n",
    "```python\n",
    "return total_res * d_ang**2. * degtorad**2 * ds * pref_rho\n",
    "```  \n",
    "\n",
    "Note that the disk proceeds similarly, as do the functions that compute the full-sky integrals for the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
